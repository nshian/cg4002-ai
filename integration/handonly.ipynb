{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ianng\\AppData\\Local\\Temp\\ipykernel_17412\\139260728.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def merge_raw_data(dir):\n",
    "    dfs = []\n",
    "    FEATURES = [\"accX1\", \"accY1\", \"accZ1\", \"gyroX1\", \"gyroY1\", \"gyroZ1\", \"accX2\", \"accY2\", \"accZ2\", \"gyroX2\", \"gyroY2\", \"gyroZ2\"]\n",
    "    LEG_COLS = [\"accX2\", \"accY2\", \"accZ2\", \"gyroX2\", \"gyroY2\", \"gyroZ2\"]\n",
    "    for f in os.scandir(dir):\n",
    "        df = pd.read_csv(f.path, header=None, names=FEATURES)\n",
    "        df = df.drop(columns=LEG_COLS)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr, skew, kurtosis\n",
    "\n",
    "def generate_features(merged_df):\n",
    "    def rms(x):\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    \n",
    "    WINDOW_SIZE = 25\n",
    "    transformed_df = merged_df.groupby(np.arange(len(merged_df)) // WINDOW_SIZE).agg({\n",
    "        \"accX1\": ['median', iqr, 'var', skew, kurtosis, rms],\n",
    "        \"accY1\": ['median', iqr, 'var', skew, kurtosis, rms],\n",
    "        \"accZ1\": ['median', iqr, 'var', skew, kurtosis, rms],\n",
    "        \"gyroX1\": ['median', iqr, 'var', skew, kurtosis, rms],\n",
    "        \"gyroY1\": ['median', iqr, 'var', skew, kurtosis, rms],\n",
    "        \"gyroZ1\": ['median', iqr, 'var', skew, kurtosis, rms],\n",
    "    })\n",
    "    transformed_df.columns = ['_'.join(col).strip() for col in transformed_df.columns.values]\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./class_dict.json', 'r') as f:\n",
    "    class_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'captain': 0,\n",
       " 'grenade': 1,\n",
       " 'hulk': 2,\n",
       " 'ironman': 3,\n",
       " 'logout': 4,\n",
       " 'random': 5,\n",
       " 'reload': 6,\n",
       " 'shangchi': 7,\n",
       " 'shield': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = './data/raw/'\n",
    "MERGED_DATA_DIR = './data/handonly/merged/'\n",
    "AUGMENTED_DATA_DIR = './data/handonly/augmented/'\n",
    "\n",
    "os.makedirs(MERGED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(AUGMENTED_DATA_DIR, exist_ok=True)\n",
    "for dir in os.scandir(RAW_DATA_DIR):\n",
    "    merged_df = merge_raw_data(dir)\n",
    "    merged_data_file_path = os.path.join(MERGED_DATA_DIR, f\"{dir.name}.csv\")\n",
    "    merged_df.to_csv(merged_data_file_path, index=False)\n",
    "    augmented_df = generate_features(merged_df)\n",
    "    augmented_df['class'] = class_dict[dir.name]\n",
    "    augmented_data_file_path = os.path.join(AUGMENTED_DATA_DIR, f\"{dir.name}.csv\")\n",
    "    augmented_df.to_csv(augmented_data_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "AUGMENTED_DATA_DIR = './data/handonly/augmented/'\n",
    "final_dfs = []\n",
    "for f in os.scandir(AUGMENTED_DATA_DIR):\n",
    "    df = pd.read_csv(f.path)\n",
    "    final_dfs.append(df)\n",
    "final_df = pd.concat(final_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accX1_median</th>\n",
       "      <th>accX1_iqr</th>\n",
       "      <th>accX1_var</th>\n",
       "      <th>accX1_skew</th>\n",
       "      <th>accX1_kurtosis</th>\n",
       "      <th>accX1_rms</th>\n",
       "      <th>accY1_median</th>\n",
       "      <th>accY1_iqr</th>\n",
       "      <th>accY1_var</th>\n",
       "      <th>accY1_skew</th>\n",
       "      <th>...</th>\n",
       "      <th>gyroY1_skew</th>\n",
       "      <th>gyroY1_kurtosis</th>\n",
       "      <th>gyroY1_rms</th>\n",
       "      <th>gyroZ1_median</th>\n",
       "      <th>gyroZ1_iqr</th>\n",
       "      <th>gyroZ1_var</th>\n",
       "      <th>gyroZ1_skew</th>\n",
       "      <th>gyroZ1_kurtosis</th>\n",
       "      <th>gyroZ1_rms</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.871</td>\n",
       "      <td>3.979</td>\n",
       "      <td>139.607699</td>\n",
       "      <td>0.076064</td>\n",
       "      <td>-0.380109</td>\n",
       "      <td>11.651967</td>\n",
       "      <td>-17.024</td>\n",
       "      <td>9.955</td>\n",
       "      <td>25.759357</td>\n",
       "      <td>0.070716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031852</td>\n",
       "      <td>-0.379493</td>\n",
       "      <td>2.506001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.081</td>\n",
       "      <td>8.762225</td>\n",
       "      <td>-0.093991</td>\n",
       "      <td>-0.748402</td>\n",
       "      <td>2.908340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.647</td>\n",
       "      <td>2.841</td>\n",
       "      <td>107.880509</td>\n",
       "      <td>-0.003239</td>\n",
       "      <td>0.186298</td>\n",
       "      <td>10.400923</td>\n",
       "      <td>-9.488</td>\n",
       "      <td>9.873</td>\n",
       "      <td>25.779247</td>\n",
       "      <td>-0.381849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120597</td>\n",
       "      <td>-0.570993</td>\n",
       "      <td>2.502437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.069</td>\n",
       "      <td>6.360700</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>2.476042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.463</td>\n",
       "      <td>6.225</td>\n",
       "      <td>98.215398</td>\n",
       "      <td>0.253025</td>\n",
       "      <td>0.405055</td>\n",
       "      <td>10.059064</td>\n",
       "      <td>-9.705</td>\n",
       "      <td>9.988</td>\n",
       "      <td>24.852623</td>\n",
       "      <td>-0.399810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168045</td>\n",
       "      <td>-0.487042</td>\n",
       "      <td>2.447198</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.858</td>\n",
       "      <td>6.853012</td>\n",
       "      <td>-0.111923</td>\n",
       "      <td>-0.199015</td>\n",
       "      <td>2.630570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.009</td>\n",
       "      <td>106.646756</td>\n",
       "      <td>0.054148</td>\n",
       "      <td>0.068139</td>\n",
       "      <td>10.133569</td>\n",
       "      <td>-9.621</td>\n",
       "      <td>9.981</td>\n",
       "      <td>26.002545</td>\n",
       "      <td>-0.219957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.075297</td>\n",
       "      <td>2.401846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>5.474714</td>\n",
       "      <td>-0.040530</td>\n",
       "      <td>0.247596</td>\n",
       "      <td>2.392161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.320</td>\n",
       "      <td>135.752353</td>\n",
       "      <td>0.054907</td>\n",
       "      <td>-0.386807</td>\n",
       "      <td>11.416073</td>\n",
       "      <td>-9.614</td>\n",
       "      <td>9.957</td>\n",
       "      <td>26.740367</td>\n",
       "      <td>-0.102253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>-0.286870</td>\n",
       "      <td>2.565400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.719</td>\n",
       "      <td>7.711332</td>\n",
       "      <td>-0.090902</td>\n",
       "      <td>-0.551575</td>\n",
       "      <td>2.727575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>-2.727</td>\n",
       "      <td>4.607</td>\n",
       "      <td>9.867046</td>\n",
       "      <td>-0.489387</td>\n",
       "      <td>-0.726773</td>\n",
       "      <td>5.178281</td>\n",
       "      <td>-9.479</td>\n",
       "      <td>10.774</td>\n",
       "      <td>31.893133</td>\n",
       "      <td>0.609979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686881</td>\n",
       "      <td>-0.801199</td>\n",
       "      <td>1.267435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.629</td>\n",
       "      <td>2.102231</td>\n",
       "      <td>-0.472117</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>1.477227</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>-4.864</td>\n",
       "      <td>5.152</td>\n",
       "      <td>14.448643</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.650035</td>\n",
       "      <td>6.060480</td>\n",
       "      <td>-8.902</td>\n",
       "      <td>10.755</td>\n",
       "      <td>32.303524</td>\n",
       "      <td>0.410515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419119</td>\n",
       "      <td>0.339695</td>\n",
       "      <td>1.199870</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.463</td>\n",
       "      <td>3.541341</td>\n",
       "      <td>0.075142</td>\n",
       "      <td>-0.665857</td>\n",
       "      <td>1.852816</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>-4.855</td>\n",
       "      <td>5.874</td>\n",
       "      <td>9.937312</td>\n",
       "      <td>-0.281087</td>\n",
       "      <td>-0.911004</td>\n",
       "      <td>5.802308</td>\n",
       "      <td>-8.104</td>\n",
       "      <td>10.854</td>\n",
       "      <td>34.659530</td>\n",
       "      <td>0.492632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140064</td>\n",
       "      <td>-0.513824</td>\n",
       "      <td>0.935372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.718</td>\n",
       "      <td>4.213747</td>\n",
       "      <td>-0.491817</td>\n",
       "      <td>-0.367868</td>\n",
       "      <td>2.012744</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>-4.180</td>\n",
       "      <td>5.126</td>\n",
       "      <td>8.316582</td>\n",
       "      <td>-0.482818</td>\n",
       "      <td>-1.005024</td>\n",
       "      <td>5.610120</td>\n",
       "      <td>-9.431</td>\n",
       "      <td>10.223</td>\n",
       "      <td>29.303554</td>\n",
       "      <td>0.379150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.607597</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>1.442584</td>\n",
       "      <td>0.133</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.168481</td>\n",
       "      <td>-0.186935</td>\n",
       "      <td>-0.592447</td>\n",
       "      <td>1.126833</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>-4.422</td>\n",
       "      <td>5.045</td>\n",
       "      <td>11.784201</td>\n",
       "      <td>-0.382385</td>\n",
       "      <td>-0.407558</td>\n",
       "      <td>5.999554</td>\n",
       "      <td>-7.681</td>\n",
       "      <td>9.686</td>\n",
       "      <td>25.525488</td>\n",
       "      <td>0.230540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382614</td>\n",
       "      <td>-0.439519</td>\n",
       "      <td>1.554342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.637801</td>\n",
       "      <td>0.034775</td>\n",
       "      <td>-0.659670</td>\n",
       "      <td>1.260918</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accX1_median  accX1_iqr   accX1_var  accX1_skew  accX1_kurtosis  \\\n",
       "0           -0.871      3.979  139.607699    0.076064       -0.380109   \n",
       "1           -0.647      2.841  107.880509   -0.003239        0.186298   \n",
       "2           -1.463      6.225   98.215398    0.253025        0.405055   \n",
       "3            0.000      2.009  106.646756    0.054148        0.068139   \n",
       "4            0.000      2.320  135.752353    0.054907       -0.386807   \n",
       "...            ...        ...         ...         ...             ...   \n",
       "3195        -2.727      4.607    9.867046   -0.489387       -0.726773   \n",
       "3196        -4.864      5.152   14.448643   -0.103638       -0.650035   \n",
       "3197        -4.855      5.874    9.937312   -0.281087       -0.911004   \n",
       "3198        -4.180      5.126    8.316582   -0.482818       -1.005024   \n",
       "3199        -4.422      5.045   11.784201   -0.382385       -0.407558   \n",
       "\n",
       "      accX1_rms  accY1_median  accY1_iqr  accY1_var  accY1_skew  ...  \\\n",
       "0     11.651967       -17.024      9.955  25.759357    0.070716  ...   \n",
       "1     10.400923        -9.488      9.873  25.779247   -0.381849  ...   \n",
       "2     10.059064        -9.705      9.988  24.852623   -0.399810  ...   \n",
       "3     10.133569        -9.621      9.981  26.002545   -0.219957  ...   \n",
       "4     11.416073        -9.614      9.957  26.740367   -0.102253  ...   \n",
       "...         ...           ...        ...        ...         ...  ...   \n",
       "3195   5.178281        -9.479     10.774  31.893133    0.609979  ...   \n",
       "3196   6.060480        -8.902     10.755  32.303524    0.410515  ...   \n",
       "3197   5.802308        -8.104     10.854  34.659530    0.492632  ...   \n",
       "3198   5.610120        -9.431     10.223  29.303554    0.379150  ...   \n",
       "3199   5.999554        -7.681      9.686  25.525488    0.230540  ...   \n",
       "\n",
       "      gyroY1_skew  gyroY1_kurtosis  gyroY1_rms  gyroZ1_median  gyroZ1_iqr  \\\n",
       "0       -0.031852        -0.379493    2.506001          0.000       1.081   \n",
       "1       -0.120597        -0.570993    2.502437          0.000       1.069   \n",
       "2       -0.168045        -0.487042    2.447198          0.156       0.858   \n",
       "3       -0.026332        -0.075297    2.401846          0.000       0.946   \n",
       "4        0.079260        -0.286870    2.565400          0.000       1.719   \n",
       "...           ...              ...         ...            ...         ...   \n",
       "3195    -0.686881        -0.801199    1.267435          0.000       1.629   \n",
       "3196    -0.419119         0.339695    1.199870          0.000       2.463   \n",
       "3197    -0.140064        -0.513824    0.935372          0.000       2.718   \n",
       "3198    -0.607597         0.014847    1.442584          0.133       1.099   \n",
       "3199    -0.382614        -0.439519    1.554342          0.000       1.383   \n",
       "\n",
       "      gyroZ1_var  gyroZ1_skew  gyroZ1_kurtosis  gyroZ1_rms  class  \n",
       "0       8.762225    -0.093991        -0.748402    2.908340      0  \n",
       "1       6.360700    -0.119359        -0.024385    2.476042      0  \n",
       "2       6.853012    -0.111923        -0.199015    2.630570      0  \n",
       "3       5.474714    -0.040530         0.247596    2.392161      0  \n",
       "4       7.711332    -0.090902        -0.551575    2.727575      0  \n",
       "...          ...          ...              ...         ...    ...  \n",
       "3195    2.102231    -0.472117        -0.180591    1.477227      8  \n",
       "3196    3.541341     0.075142        -0.665857    1.852816      8  \n",
       "3197    4.213747    -0.491817        -0.367868    2.012744      8  \n",
       "3198    1.168481    -0.186935        -0.592447    1.126833      8  \n",
       "3199    1.637801     0.034775        -0.659670    1.260918      8  \n",
       "\n",
       "[3200 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should not print anything, indicating no missing values\n",
    "missing_data_counts = final_df.isna().sum()\n",
    "for column, count in missing_data_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{column}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_df['class'].to_numpy()\n",
    "x = final_df.drop(['class'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified sampling to get good ratio of classes\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 300]\n",
      " [  1 300]\n",
      " [  2 300]\n",
      " [  3 300]\n",
      " [  4 160]\n",
      " [  5 300]\n",
      " [  6 300]\n",
      " [  7 300]\n",
      " [  8 300]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 75]\n",
      " [ 1 75]\n",
      " [ 2 75]\n",
      " [ 3 75]\n",
      " [ 4 40]\n",
      " [ 5 75]\n",
      " [ 6 75]\n",
      " [ 7 75]\n",
      " [ 8 75]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "x_train = torch.from_numpy(x_train).to(torch.float32)\n",
    "x_test = torch.from_numpy(x_test).to(torch.float32)\n",
    "y_train = torch.from_numpy(y_train).to(torch.long)\n",
    "y_test = torch.from_numpy(y_test).to(torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_prob=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = x_train.shape[1]\n",
    "HIDDEN_SIZE1 = 128\n",
    "HIDDEN_SIZE2 = 64\n",
    "OUTPUT_SIZE = 9\n",
    "DROPOUT_PROB = 0.2\n",
    "\n",
    "model = Model(INPUT_SIZE, HIDDEN_SIZE1, HIDDEN_SIZE2, OUTPUT_SIZE, DROPOUT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.3763, Train Accuracy: 52.11%\n",
      "Epoch 2/30, Train Loss: 0.7275, Train Accuracy: 75.78%\n",
      "Epoch 3/30, Train Loss: 0.5438, Train Accuracy: 82.77%\n",
      "Epoch 4/30, Train Loss: 0.4259, Train Accuracy: 86.88%\n",
      "Epoch 5/30, Train Loss: 0.3398, Train Accuracy: 89.80%\n",
      "Epoch 6/30, Train Loss: 0.2809, Train Accuracy: 91.13%\n",
      "Epoch 7/30, Train Loss: 0.2731, Train Accuracy: 91.64%\n",
      "Epoch 8/30, Train Loss: 0.2450, Train Accuracy: 91.99%\n",
      "Epoch 9/30, Train Loss: 0.2191, Train Accuracy: 93.12%\n",
      "Epoch 10/30, Train Loss: 0.2118, Train Accuracy: 93.16%\n",
      "Epoch 11/30, Train Loss: 0.1916, Train Accuracy: 93.98%\n",
      "Epoch 12/30, Train Loss: 0.2221, Train Accuracy: 93.12%\n",
      "Epoch 13/30, Train Loss: 0.1957, Train Accuracy: 93.83%\n",
      "Epoch 14/30, Train Loss: 0.1738, Train Accuracy: 94.73%\n",
      "Epoch 15/30, Train Loss: 0.1970, Train Accuracy: 93.63%\n",
      "Epoch 16/30, Train Loss: 0.1555, Train Accuracy: 94.96%\n",
      "Epoch 17/30, Train Loss: 0.1670, Train Accuracy: 94.18%\n",
      "Epoch 18/30, Train Loss: 0.1661, Train Accuracy: 94.30%\n",
      "Epoch 19/30, Train Loss: 0.1768, Train Accuracy: 94.65%\n",
      "Epoch 20/30, Train Loss: 0.1371, Train Accuracy: 95.55%\n",
      "Epoch 21/30, Train Loss: 0.1490, Train Accuracy: 95.20%\n",
      "Epoch 22/30, Train Loss: 0.1433, Train Accuracy: 95.70%\n",
      "Epoch 23/30, Train Loss: 0.1396, Train Accuracy: 95.82%\n",
      "Epoch 24/30, Train Loss: 0.1355, Train Accuracy: 95.39%\n",
      "Epoch 25/30, Train Loss: 0.1347, Train Accuracy: 95.66%\n",
      "Epoch 26/30, Train Loss: 0.1392, Train Accuracy: 95.31%\n",
      "Epoch 27/30, Train Loss: 0.1659, Train Accuracy: 94.92%\n",
      "Epoch 28/30, Train Loss: 0.1539, Train Accuracy: 95.82%\n",
      "Epoch 29/30, Train Loss: 0.1267, Train Accuracy: 96.09%\n",
      "Epoch 30/30, Train Loss: 0.1223, Train Accuracy: 96.48%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100. * correct / total\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def evaluate(model, x_test, y_test):\n",
    "    start_time = time.time()\n",
    "    print(f'Evaluating model performance for test set of size {len(x_test)}')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test)\n",
    "        _, y_pred = torch.max(y_pred, 1)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")\n",
    "    print(f'Accuracy: {100. * accuracy_score(y_test, y_pred)}%')\n",
    "    print(f'Confusion matrix:\\n {confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'Classification report:\\n {classification_report(y_test, y_pred)}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model performance for test set of size 640\n",
      "Execution time: 0.0010006427764892578 seconds\n",
      "Accuracy: 97.1875%\n",
      "Confusion matrix:\n",
      " [[72  0  0  0  0  2  0  0  1]\n",
      " [ 0 74  0  0  0  1  0  0  0]\n",
      " [ 1  0 74  0  0  0  0  0  0]\n",
      " [ 0  0  0 75  0  0  0  0  0]\n",
      " [ 0  0  0  0 40  0  0  0  0]\n",
      " [ 1  0  0  1  0 66  3  0  4]\n",
      " [ 1  0  0  1  0  0 73  0  0]\n",
      " [ 0  0  0  0  0  0  0 75  0]\n",
      " [ 0  1  0  0  0  1  0  0 73]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        75\n",
      "           1       0.99      0.99      0.99        75\n",
      "           2       1.00      0.99      0.99        75\n",
      "           3       0.97      1.00      0.99        75\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       0.94      0.88      0.91        75\n",
      "           6       0.96      0.97      0.97        75\n",
      "           7       1.00      1.00      1.00        75\n",
      "           8       0.94      0.97      0.95        75\n",
      "...\n",
      "    accuracy                           0.97       640\n",
      "   macro avg       0.97      0.97      0.97       640\n",
      "weighted avg       0.97      0.97      0.97       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "dt_string = datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S\")\n",
    "torch.save(model.state_dict(), f'models/mlp_handonly_{dt_string}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_filename = f'models/mlp_handonly_{dt_string}_params.txt'\n",
    "with open(model_params_filename, 'w+') as file:\n",
    "    for name, param in model.named_parameters():\n",
    "        file.write(f'Layer: {name}\\n')\n",
    "        # Convert the parameter values to a NumPy array\n",
    "        param_array = param.data.cpu().numpy()\n",
    "        \n",
    "        if \"weight\" in name:\n",
    "            for row in param_array:\n",
    "                file.write('{')\n",
    "                for val in row:\n",
    "                    file.write(f'%.6f, ' % val)\n",
    "                file.write('},')\n",
    "                file.write('\\n')\n",
    "        else: # bias\n",
    "            file.write('{')\n",
    "            for val in param_array:\n",
    "                file.write(f'%.6f, ' % val)\n",
    "            file.write('},')\n",
    "            file.write('\\n')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6100e+00,  1.2140e+01,  1.1812e+02,  3.5350e-01, -1.5457e-01,\n",
      "         1.1328e+01, -1.0072e+01,  1.0187e+01,  2.7264e+01, -2.0658e-01,\n",
      "        -1.6793e+00,  1.4727e+01, -9.3350e+00,  7.9940e+00,  3.1209e+01,\n",
      "        -4.9545e-01, -9.3515e-01,  1.3203e+01,  0.0000e+00,  1.1290e+00,\n",
      "         2.6564e+00,  1.5855e-01,  1.0658e+00,  1.6473e+00,  0.0000e+00,\n",
      "         1.3580e+00,  4.1928e+00,  5.1308e-01,  6.8582e-02,  2.0064e+00,\n",
      "         0.0000e+00,  3.1750e+00,  9.1346e+00,  2.3218e-01, -9.3537e-01,\n",
      "         2.9838e+00])\n",
      "tensor(8)\n",
      "tensor([-0.1950,  4.5950, 46.6532,  0.1750,  1.0789,  6.6939, -9.2700, 12.0760,\n",
      "        57.9847,  0.2038, -1.3027,  8.5476, -8.2240,  6.3540, 71.4197, -0.7057,\n",
      "         1.4705, 10.4061,  0.0000,  1.6010,  4.9837,  0.3139, -0.2602,  2.2711,\n",
      "         0.0000,  0.3460,  2.7714, -0.9184,  0.8045,  1.6932,  0.0000,  0.9150,\n",
      "         1.8829,  0.8149,  1.5251,  1.4587])\n",
      "tensor(3)\n",
      "tensor([-1.5980,  2.4720, 13.6490, -0.9622,  1.8812,  4.2227, -9.8340,  7.4380,\n",
      "        20.4778, -0.9519, -0.9282, 13.2916, -5.6720,  5.3410, 31.1594,  0.2460,\n",
      "        -0.1771,  6.8635,  0.0000,  0.8610,  2.0223, -0.0826,  0.5321,  1.3941,\n",
      "        -0.1830,  2.0570,  1.9080, -0.6718, -0.4634,  1.5734,  0.0000,  1.1880,\n",
      "         6.8149, -0.2873, -0.5137,  2.5605])\n",
      "tensor(7)\n",
      "tensor([-7.8690,  0.5580,  0.7450,  0.7419,  1.2144,  7.8088, -3.2330,  0.8700,\n",
      "         0.5966,  0.4742, -0.2816,  3.3149, -4.2260,  0.4350,  0.3232, -0.1578,\n",
      "        -0.5531,  4.2566,  0.0000,  0.1020,  0.0641,  1.0066,  1.5695,  0.2596,\n",
      "         0.0000,  0.2540,  0.0628,  0.2737, -0.0505,  0.2604,  0.0000,  0.1050,\n",
      "         0.0431,  0.5743,  1.0045,  0.2040])\n",
      "tensor(5)\n",
      "tensor([ -3.0750,   9.0500, 101.1731,   0.4402,   0.3127,  10.9931, -11.0500,\n",
      "          7.2080,  16.4914,  -0.5470,  -1.3250,  13.6605,  -9.5910,   2.1520,\n",
      "         49.3128,  -0.3996,   3.0189,  11.7207,   0.0000,   1.3250,   4.6989,\n",
      "         -0.3383,   0.2982,   2.1239,  -0.1270,   1.0920,   2.0009,  -1.2492,\n",
      "          2.2118,   1.3874,   0.1030,   3.7300,   7.6525,  -0.2260,  -0.6177,\n",
      "          2.8205])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_test[i])\n",
    "    print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "x_test = x_test.tolist()\n",
    "y_test = y_test.tolist()\n",
    "labelled_test_data = [{\"x\": x, \"y\": y} for x, y in list(zip(x_test, y_test))]\n",
    "with open('./data/handonly/test_data.json', 'w+') as test_data_json:\n",
    "    json.dump(labelled_test_data, test_data_json, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
